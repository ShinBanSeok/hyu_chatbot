import os
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

# ğŸ”¹ .envì— OPENAI_API_KEYê°€ ë“¤ì–´ ìˆì–´ì•¼ í•¨
load_dotenv()

# 1. DB ë¡œë”©
persist_directory = "./hyuwiki_vectorstore"  # ë²¡í„° DB ì €ì¥ëœ ê²½ë¡œ
embedding_model = OpenAIEmbeddings()
vectordb = Chroma(
    persist_directory=persist_directory, embedding_function=embedding_model
)
retriever = vectordb.as_retriever()

docs = vectordb.similarity_search("ì„œìš¸ìº í¼ìŠ¤ ì •ë³´ì‹œìŠ¤í…œ êµìˆ˜", k=3)
# 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (Few-shot ì—†ì´)
prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
ë‹¹ì‹ ì€ í•œì–‘ëŒ€í•™êµì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ì •ë‹µì„ ë‹µí•˜ì„¸ìš”.

ê²€ìƒ‰ ë¬¸ì„œ ë‚´ìš©:
{context}

ì§ˆë¬¸: {question}

ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”:
""",
)

# 3. QA ì²´ì¸ êµ¬ì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(temperature=0),
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": prompt_template},
)

# 4. ì˜ˆì‹œ ì§ˆë¬¸
query = "ì •ë³´ì‹œìŠ¤í…œ í•™ê³¼ êµìˆ˜ê°€ ëˆ„êµ¬ì•¼?"
response = qa_chain.run(query)
print("ğŸ¤– ë‹µë³€:", response)
